{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'/C:/Users/luiza/OneDrive/Área de Trabalho/Python-Prep/07 - Clases & OOP/herramientas.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herramientas as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39mPilar\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\luiza\\OneDrive\\Área de Trabalho\\Python-Prep\\08 - Error Handling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h1 = h.Herramientas('Pilar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\luiza\\\\OneDrive\\\\Área de Trabalho\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros esperados son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.6, 37.4, 41.0, 42.8, 35.6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius','farenheit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        lis = [1,2,1,3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.062s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2552db86020>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39mPili\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\luiza\\OneDrive\\Área de Trabalho\\Python-Prep\\08 - Error Handling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('Pili')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primos1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        primos = h1.verifica_primo()\n",
    "        primos_esperado = [True, True, False, False, True]\n",
    "        self.assertEqual(primos, primos_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\luiza\\\\OneDrive\\\\Área de Trabalho\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.053s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2552db85c30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_conversion1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        grados = h1.conversion_grados('celsius','farenheit')\n",
    "        grados_esperado = [35.6, 37.4, 46.4, 50.0, 55.4]\n",
    "        self.assertEqual(grados, grados_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\luiza\\\\OneDrive\\\\Área de Trabalho\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.054s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2552e2220b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase4(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_factorial(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        factorial = h1.factorial()\n",
    "        factorial_esperado = [2, 6, 40320, 3628800, 6227020800]\n",
    "        self.assertEqual(factorial, factorial_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\luiza\\\\OneDrive\\\\Área de Trabalho\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3) ... ok\n",
      "test_verifica_factorial (__main__.ProbandoMiClase4) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.069s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2552dbe4a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
